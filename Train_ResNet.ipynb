{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation on breeds using the fine-tuned ResNet convolutional neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from settings import get_train_dataloader, get_criterion, get_optimizer\n",
    "from functions import train_model\n",
    "from models import getResNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Justine_B\\OneDrive\\Documents\\UTC\\GI05\\DL\\DeepLearningAndGenerativeModelsCourse-main\\Project\\settings.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_imgs = torch.stack([torch.tensor(img, dtype=torch.float32) for img in train_imgs])\n",
      "c:\\Users\\Justine_B\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Justine_B\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "transform_id = 1\n",
    "batch_size = 4\n",
    "\n",
    "# Get the training DataLoader with data transformation (1st parameter) and batch size (2nd parameter)\n",
    "trainloader = get_train_dataloader(transform_id,batch_size)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = getResNetModel(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "[0,   200] loss: 0.146\n",
      "[0,   400] loss: 0.142\n",
      "[0,   600] loss: 0.143\n",
      "[0,   800] loss: 0.144\n",
      "[0,  1000] loss: 0.148\n",
      "[0,  1200] loss: 0.131\n",
      "[0,  1400] loss: 0.136\n",
      "Epoch 1\n",
      "[1,   200] loss: 0.140\n",
      "[1,   400] loss: 0.130\n",
      "[1,   600] loss: 0.133\n",
      "[1,   800] loss: 0.140\n",
      "[1,  1000] loss: 0.142\n",
      "[1,  1200] loss: 0.133\n",
      "[1,  1400] loss: 0.134\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_function_id = 1\n",
    "optimizer_id = 1\n",
    "PATH = './res/ResNet_T1C1O1.pth'\n",
    "\n",
    "# Get the Loss criterion with the given id in parameter\n",
    "criterion = get_criterion(loss_function_id)\n",
    "# Get the optimizer with the given id in parameter\n",
    "optimizer = get_optimizer(list(resnet.parameters()),optimizer_id)\n",
    "resnet.load_state_dict(torch.load(PATH))\n",
    "# Train the model using the specified criterion, optimizer, DataLoader, device, and number of epochs\n",
    "train_model(resnet, criterion, optimizer, trainloader, device, 2)\n",
    "# Save the state dictionary of the trained ResNet model to the specified file path\n",
    "torch.save(resnet.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
